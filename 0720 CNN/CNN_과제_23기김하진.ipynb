{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZxvpsbK_KPA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFAX7zz4Q7TW",
        "outputId": "cbc7da8c-f5b2-486b-81fb-6c889749a844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print('device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMrkSUyKQuaC"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "\n",
        "# Custom IPython progress bar for training\n",
        "class ProgressMonitor(object):\n",
        "\n",
        "    tmpl = \"\"\"\n",
        "        <table style=\"width: 100%;\">\n",
        "            <tbody>\n",
        "                <tr>\n",
        "                    <td style=\"width: 30%;\">\n",
        "                     <b>Loss: {loss:0.4f}</b> &nbsp&nbsp&nbsp {value} / {length}\n",
        "                    </td>\n",
        "                    <td style=\"width: 70%;\">\n",
        "                        <progress value='{value}' max='{length}', style='width: 100%'>{value}</progress>\n",
        "                    </td>\n",
        "                </tr>\n",
        "            </tbody>\n",
        "        </table>\n",
        "        \"\"\"\n",
        "\n",
        "    def __init__(self, length):\n",
        "        self.length = length\n",
        "        self.count = 0\n",
        "        self.display = display(self.html(0, 0), display_id=True)\n",
        "\n",
        "    def html(self, count, loss):\n",
        "        return HTML(self.tmpl.format(length=self.length, value=count, loss=loss))\n",
        "\n",
        "    def update(self, count, loss):\n",
        "        self.count += count\n",
        "        self.display.update(self.html(self.count, loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZgdPtMKB2kP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756a356d-b64f-466a-ed71-a192e0d2ce2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29591070.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform_train = T.Compose( [T.RandomCrop(32, padding=4), T.ToTensor(), T.Normalize( (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) )] )\n",
        "transform_test = T.Compose( [T.ToTensor(), T.Normalize( (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) )] )\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=transform_train )\n",
        "test_set = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=transform_test )\n",
        "\n",
        "classes = train_set.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YmtRUX2Chc-",
        "outputId": "9538173c-2d5b-4aa5-dc99-269223f679e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "print(train_set.data.shape)\n",
        "print(test_set.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LjBgQWTAQBi"
      },
      "outputs": [],
      "source": [
        "# 과제 1- SimpleCNN의 오류를 없애라!\n",
        "# Hint- matrix의 size를 주의! maxpooling은 size를 1/2배한다. filter의 size도 중요\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "\n",
        "\n",
        "            #### 입력 이미지 크기 32x32x3\n",
        "\n",
        "            nn.Conv2d( in_channels=3, out_channels=64, kernel_size=2, padding=1 ),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d( in_channels=64, out_channels=64, kernel_size=2, padding=1 ),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d( in_channels=64, out_channels=128, kernel_size=2, padding=1 ),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "\n",
        "            nn.Linear( 128 * 4 * 4, 500),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(500, 10),\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv_layers(x)\n",
        "\n",
        "        x = x.view( x.size(0), -1 ) # flatten\n",
        "\n",
        "        x = self.fc_layers(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lKWDBrDqNNH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "997c6a3e-792d-4c76-e390-cd8096a95e60"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-809b375c0d23>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-28c4fc44b41f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (7x10368 and 2048x500)"
          ]
        }
      ],
      "source": [
        "# 모델 테스트\n",
        "# 텐서의 사이즈가 (7, 10)이 나오면 성공\n",
        "# 현재는 오류가 뜨는 상황! matrix size를 잘 맞춰서 이 코드가 정상적으로 구동되면 성공입니다.\n",
        "\n",
        "temp = SimpleCNN()\n",
        "output = torch.randn( 7, 3, 32, 32)\n",
        "\n",
        "print( temp(output).size() )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 실습 2- Resnet 구현(선택)\n",
        "# Hint- layer를 지나간 뒤 input을 더해주어야 한다, stride말고 maxpool로 size 줄여도 괜찮습니다.\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "  def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "VqA6Q2pBBDyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resnet 모델 테스트\n",
        "# 텐서의 사이즈가 (7, 10)이 나오면 성공\n",
        "\n",
        "temp = Resnet()\n",
        "output = torch.randn( 7, 3, 32, 32)\n",
        "\n",
        "print( temp(output).size() )\n"
      ],
      "metadata": {
        "id": "gMYDgEURCsIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtKz3gmF_NTT"
      },
      "outputs": [],
      "source": [
        "batch_size = 128 # 배치 사이즈\n",
        "learning_rate = 0.01 # 학습률\n",
        "num_epochs = 30 # 에폭 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqBcfSB9QQbW"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2Fe9zzeQzRB"
      },
      "outputs": [],
      "source": [
        "# 원하는 모델을 돌려보세요\n",
        "\n",
        "model = SimpleCNN()\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcuWxEnnRfGX"
      },
      "outputs": [],
      "source": [
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer 선정\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHkcPL-RRmEA"
      },
      "outputs": [],
      "source": [
        "from statistics import mean\n",
        "\n",
        "def train(optimizer, model, num_epochs=10, first_epoch=1):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    for epoch in range(first_epoch, first_epoch + num_epochs):\n",
        "        print('Epoch', epoch)\n",
        "\n",
        "        # train phase\n",
        "        model.train()\n",
        "\n",
        "        # create a progress bar\n",
        "        progress = ProgressMonitor(length=len(train_set))\n",
        "\n",
        "        # keep track of predictions\n",
        "        correct_train = 0\n",
        "\n",
        "        batch_losses = []\n",
        "\n",
        "        for batch, targets in train_loader:\n",
        "\n",
        "            # Move the training data to the GPU\n",
        "            batch = batch.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # clear previous gradient computation\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward propagation\n",
        "            outputs = model(batch)\n",
        "\n",
        "            # calculate the loss\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # backpropagate to compute gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # update model weights\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_losses.append(loss.item())\n",
        "\n",
        "            # accumulate correct count\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_train += torch.sum(preds == targets.data)\n",
        "\n",
        "            # update progress bar\n",
        "            progress.update(batch.shape[0], mean(batch_losses) )\n",
        "\n",
        "\n",
        "        train_losses.append( mean(batch_losses))\n",
        "\n",
        "\n",
        "        # test phase\n",
        "        model.eval()\n",
        "\n",
        "        y_pred = []\n",
        "\n",
        "        correct_test = 0\n",
        "\n",
        "        # We don't need gradients for test, so wrap in\n",
        "        # no_grad to save memory\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for batch, targets in test_loader:\n",
        "\n",
        "                # Move the training batch to the GPU\n",
        "                batch = batch.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                # forward propagation\n",
        "                outputs = model(batch)\n",
        "\n",
        "                # calculate the loss\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                # save predictions\n",
        "                y_pred.extend( outputs.argmax(dim=1).cpu().numpy() )\n",
        "\n",
        "                # accumulate correct count\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct_test += torch.sum(preds == targets.data)\n",
        "\n",
        "\n",
        "        # Calculate accuracy\n",
        "        train_acc = correct_train.item() / train_set.data.shape[0]\n",
        "        test_acc = correct_test.item() / test_set.data.shape[0]\n",
        "\n",
        "        print('Training accuracy: {:.2f}%'.format(float(train_acc) * 100))\n",
        "        print('Test accuracy: {:.2f}%\\n'.format(float(test_acc) * 100))\n",
        "\n",
        "\n",
        "    return train_losses, test_losses, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPgk2q20Rq6Q"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "train_losses, test_losses, y_pred = train(optimizer, model, num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기까지 진행하고! ipynb 파일 제출해주세요."
      ],
      "metadata": {
        "id": "FBy1PpdRiK7b"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}